View(recognition_df)
494/2
perfect <- recognition_df %>% filter(accuracy == 1) %>%
filter(d_setsize != 0)
View(perfect)
perfect <- recognition_df %>% filter(accuracy == 1) %>%
filter(d_setsize != 0) %>%
filter(reopeat. == 1)
perfect <- recognition_df %>% filter(accuracy == 1) %>%
filter(d_setsize != 0) %>%
filter(repeat. == 1)
View(perfect)
123/484
123/494
num <- recognition_df %>% flter(d_setsize!=0, repeat. == 1)
num <- recognition_df %>% filter(d_setsize!=0, repeat. == 1)
123/228
recognition_df <- merge(recognition_data, q2_data) %>%
filter(block == 1) %>%
group_by(tloc, sub_id_2, repeat., d_setsize) %>%
filter(sub_id_2 != 19 & sub_id_2 != 24) %>%
summarise(q1 = mean(q1),
noticed = mean(q2_resp),
accuracy = mean(Hit_recog),
percentage = mean(q2),
conf = mean(Confidence_recog))
recognition_df <- merge(recognition_data, q2_data) %>%
# filter(block == 1) %>%
group_by(tloc, sub_id_2, repeat., d_setsize) %>%
filter(sub_id_2 != 19 & sub_id_2 != 24) %>%
summarise(q1 = mean(q1),
noticed = mean(q2_resp),
accuracy = mean(Hit_recog),
percentage = mean(q2),
conf = mean(Confidence_recog))
perfect <- recognition_df %>% filter(accuracy == 1) %>%
filter(d_setsize != 0) %>%
filter(repeat. == 1)
recognition_df <- merge(recognition_data, q2_data) %>%
filter(block == 1) %>%
group_by(tloc, sub_id_2, repeat., d_setsize) %>%
filter(sub_id_2 != 19 & sub_id_2 != 24) %>%
summarise(q1 = mean(q1),
noticed = mean(q2_resp),
accuracy = mean(Hit_recog),
percentage = mean(q2),
conf = mean(Confidence_recog))
perfect <- recognition_df %>% filter(accuracy == 1) %>%
filter(d_setsize != 0) %>%
filter(repeat. == 1)
recognition_df <- merge(recognition_data, q2_data) %>%
# filter(block == 1) %>%
group_by(tloc, sub_id_2, repeat., d_setsize) %>%
filter(sub_id_2 != 19 & sub_id_2 != 24) %>%
summarise(q1 = mean(q1),
noticed = mean(q2_resp),
accuracy = mean(Hit_recog),
percentage = mean(q2),
conf = mean(Confidence_recog))
recognition_df <- merge(recognition_data, q2_data) %>%
# filter(block == 1) %>%
group_by(tloc, sub_id_2, repeat., d_setsize) %>%
filter(sub_id_2 != 19 & sub_id_2 != 24) %>%
summarise(q1 = mean(q1),
noticed = mean(q2_resp),
accuracy = mean(Hit_recog),
percentage = mean(q2),
conf = mean(Confidence_recog))
perfect <- recognition_df %>% filter(accuracy == 1) %>%
filter(d_setsize != 0) %>%
filter(repeat. == 1)
num <- recognition_df %>% filter(d_setsize!=0, repeat. == 1)
40/228\
40/228
mean(perfect$conf)
perfect <- recognition_df %>% filter(accuracy < 1) %>%
filter(d_setsize != 0) %>%
filter(repeat. == 1)
mean(perfect$conf)
individual_novel_rts <- clean_data %>%
group_by(display, d_setsize, sub_id) %>%
summarise(new_rt = mean(RT)) %>%
filter(sub_id != 24) %>%
filter(display == "new")
individual_repeated_rts <- clean_data %>%
filter(sub_id!= 19 & sub_id != 24) %>%
group_by(sub_id, display, tloc, d_setsize) %>%
summarise(repeat_rt = mean(RT)) %>%
filter(display == "old")
individual_cc <- merge(individual_novel_rts, individual_repeated_rts, by=c("sub_id", "d_setsize")) %>%
mutate(cc = (repeat_rt - new_rt))
individual_display_recognition <- merge(recognition_data, q2_data) %>%
filter(sub_id_2 != 19 & sub_id_2 != 24) %>%
# 19 bad subject, 24 didn't complete recognition test
group_by(sub_id_2, repeat., tloc, d_setsize) %>%
summarise(accuracy = mean(Hit_recog), conf = mean(Confidence_recog)) %>%
filter(repeat. == 1) %>%
rename(sub_id = "sub_id_2")
individual_cc_df <- merge(individual_cc, individual_display_recognition) %>%
group_by(accuracy, sub_id, d_setsize) %>%
summarise(cc = mean(cc))
individual_cc_df$d_setsize <- as.factor(individual_cc_df$d_setsize)
individual_cc_df$accuracy <- as.factor(individual_cc_df$accuracy)
ggplot(data = individual_cc_df, aes(x = accuracy, y = cc, color=d_setsize, group = d_setsize)) +
geom_violin() +
geom_jitter(shape=16, height=0, width=.2) +
geom_boxplot(width=.1, fill = "white") +
xlab("\nAccuracy on recognition test") +
ylab("Contextual cueing effect (ms)") +
# theme(legend.position='none') +
# scale_y_continuous(limits=c(-750, 1000)) +
# scale_fill_manual(values=c("#99cc99","#99cc99","#3498db", "#3498db")) +
# scale_y_continuous(limits=c(-750, 1000),
#                    breaks=seq(-750, 1000, 250),
#                    labels = every_nth(seq(-750, 1000, 250), 1, inverse=TRUE)) +
theme(axis.text.x = element_text(size=13),
axis.text.y = element_text(size=14),
axis.title.x = element_text(size=14),
axis.title.y = element_text(size=14))
(anovaBF(cc ~ accuracy, data = individual_cc_df))
1/0.09
View(individual_cc_df)
View(individual_display_recognition)
individual_display_recognition <- merge(recognition_data, q2_data) %>%
filter(sub_id_2 != 19 & sub_id_2 != 24) %>%
filter(d_setsize != 0) %>%
# 19 bad subject, 24 didn't complete recognition test
group_by(sub_id_2, repeat., tloc, d_setsize) %>%
summarise(accuracy = mean(Hit_recog), conf = mean(Confidence_recog)) %>%
filter(repeat. == 1) %>%
rename(sub_id = "sub_id_2")
individual_cc_df <- merge(individual_cc, individual_display_recognition) %>%
group_by(accuracy, sub_id, d_setsize) %>%
summarise(cc = mean(cc))
individual_cc_df$d_setsize <- as.factor(individual_cc_df$d_setsize)
individual_cc_df$accuracy <- as.factor(individual_cc_df$accuracy)
ggplot(data = individual_cc_df, aes(x = accuracy, y = cc, color=d_setsize, group = d_setsize)) +
geom_violin() +
geom_jitter(shape=16, height=0, width=.2) +
geom_boxplot(width=.1, fill = "white") +
xlab("\nAccuracy on recognition test") +
ylab("Contextual cueing effect (ms)") +
# theme(legend.position='none') +
# scale_y_continuous(limits=c(-750, 1000)) +
# scale_fill_manual(values=c("#99cc99","#99cc99","#3498db", "#3498db")) +
# scale_y_continuous(limits=c(-750, 1000),
#                    breaks=seq(-750, 1000, 250),
#                    labels = every_nth(seq(-750, 1000, 250), 1, inverse=TRUE)) +
theme(axis.text.x = element_text(size=13),
axis.text.y = element_text(size=14),
axis.title.x = element_text(size=14),
axis.title.y = element_text(size=14))
(anovaBF(cc ~ accuracy, data = individual_cc_df))
1/006967867
1/0.06967867
individual_display_recognition <- merge(recognition_data, q2_data) %>%
filter(sub_id_2 != 19 & sub_id_2 != 24) %>%
filter(d_setsize != 0) %>%
# 19 bad subject, 24 didn't complete recognition test
group_by(sub_id_2, repeat., tloc, d_setsize) %>%
summarise(accuracy = mean(Hit_recog), conf = mean(Confidence_recog)) %>%
filter(repeat. == 1) %>%
rename(sub_id = "sub_id_2") %>%
filter(accuracy == 1)
individual_display_recognition <- merge(recognition_data, q2_data) %>%
filter(sub_id_2 != 19 & sub_id_2 != 24) %>%
filter(d_setsize != 0) %>%
# 19 bad subject, 24 didn't complete recognition test
group_by(sub_id_2, repeat., tloc, d_setsize) %>%
summarise(accuracy = mean(Hit_recog), conf = mean(Confidence_recog)) %>%
filter(repeat. == 1) %>%
rename(sub_id = "sub_id_2")
1/19
rm(list=ls())
setwd('Z:/Contextual_Cueing/Experiment 3/Data')
library(tidyverse)
library(ez)
library(broom)
library(BayesFactor)
every_nth <- function(x, nth, empty = TRUE, inverse = FALSE)
{
if (!inverse) {
if(empty) {
x[1:nth == 1] <- ""
x
} else {
x[1:nth != 1]
}
} else {
if(empty) {
x[1:nth != 1] <- ""
x
} else {
x[1:nth == 1]
}
}
}
all_files = list.files(pattern=".csv")
recognition_files = list.files(pattern="recognition.csv")
search_files = setdiff(all_files, c(recognition_files, "question2_resp.csv"))
search_data <- do.call(rbind, lapply(search_files, read.csv, header=TRUE))
recognition_data <- do.call(rbind, lapply(recognition_files, read.csv, header = TRUE))
q2_data <- read.csv("question2_resp.csv") %>%
rename(sub_id_2 = "Var1",
q2_resp = "Var2")
descrip <- search_data %>%
filter(sub_id != 28) %>%
mutate(hit = ifelse(Error == 0, 1, 0)) %>%
group_by(sub_id) %>%
summarise(accuracy = mean(hit))
individual_mean_rts <- search_data %>%
filter(sub_id != 28) %>%
filter(Error == 0) %>%
group_by(sub_id) %>%
summarise(meanRT = mean(RT))
group_sd <- sd(individual_mean_rts$meanRT)
group_mean <- mean(individual_mean_rts$meanRT)
bad_subs_accuracy <- (descrip %>%
filter(accuracy<.9))$sub_id
bad_subs_rt <- (individual_mean_rts %>%
mutate(upper_sd = group_mean + (2*group_sd),
lower_sd = group_mean - (2*group_sd)) %>%
mutate(exclude = if_else(meanRT < lower_sd | meanRT > upper_sd, 1, 0)) %>%
filter(exclude == 1))$sub_id
descrip <- search_data %>%
filter(sub_id != bad_subs_rt) %>%
mutate(hit = ifelse(Error == 0, 1, 0)) %>%
group_by(sub_id) %>%
summarise(accuracy = mean(hit))
individual_mean_rts <- search_data %>%
filter(sub_id != bad_subs_rt) %>%
filter(Error == 0) %>%
group_by(sub_id) %>%
summarise(meanRT = mean(RT))
group_sd <- sd(individual_mean_rts$meanRT)
group_mean <- mean(individual_mean_rts$meanRT)
bad_subs_rt <- (individual_mean_rts %>%
mutate(upper_sd = group_mean + (2*group_sd),
lower_sd = group_mean - (2*group_sd)) %>%
mutate(exclude = if_else(meanRT < lower_sd | meanRT > upper_sd, 1, 0)) %>%
filter(exclude == 1))$sub_id
bad_subs <- 19
n_subs <- 20
clean_data <- search_data %>%
filter(!is.element(sub_id, bad_subs)) %>%
filter(Error == 0) %>%
group_by(repeat., d_setsize, sub_id) %>%
mutate(upperlimit = mean(RT) + 2.5*sd(RT), lowerlimit = mean(RT) - 2.5*sd(RT)) %>%
mutate(outlier = RT > upperlimit | RT < lowerlimit) %>%
mutate(display = if_else(repeat. == 0, 'new', 'old')) %>%
filter(outlier == FALSE) %>%
mutate(epoch = ceiling(block/5))
clean_df <- clean_data %>%
group_by(display, d_setsize, epoch, sub_id) %>%
summarise(rt = mean(RT))
clean_df$display <- as.factor(clean_df$display)
clean_df$epoch <- as.factor(clean_df$epoch)
plot_df <- clean_df %>%
group_by(display, d_setsize) %>%
summarise(mean_rt = mean(rt), sem = sd(rt/sqrt(20)))
ggplot(plot_df, aes(x=d_setsize, y=mean_rt, linetype = display, group=display)) +
geom_point(size=3, aes(shape = plot_df$display)) +
stat_smooth(method="lm", formula=y~log(x+1), se=FALSE, color='#13294b', size = 2) +
geom_errorbar(aes(ymin=mean_rt-sem, ymax=mean_rt+sem), width=2, size=1) +
xlab("Lure set size") +
ylab("RT") + coord_cartesian(ylim=c(460, 660)) +
scale_y_continuous(breaks=seq(460, 660,10),
labels = every_nth(seq(460, 660,10), 5, inverse=TRUE)) +
theme_bw() +
theme(panel.border = element_rect(linetype = 'solid', colour = 'grey', size=1.2),
text = element_text(size=28)) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
theme(legend.position="none",
axis.text=element_text(size=28)) +
theme(panel.border = element_blank())
clean_df %>% group_by(sub_id) %>% summarise(m = mean(rt))
a <- clean_df %>% group_by(sub_id) %>% summarise(m = mean(rt))
View(a)
bf <- anovaBF(rt ~ d_setsize * epoch* display, data = clean_df)
clean_df$d_setsize <- as.factor(clean_df$d_setsize)
bf <- anovaBF(rt ~ d_setsize * epoch* display, data = clean_df)
bs
bf
clean_df$epoch <- as.factor(clean_df$epoch)
clean_df$d_setsize <- as.factor(clean_df$d_setsize)
ezANOVA(clean_df,
dv = rt,
wid = sub_id,
within = c(epoch, d_setsize, display))
bf
1/0.09122876
bf <- anovaBF(rt ~  display, data = clean_df)
bf
1/0.09122876
rm(list=ls())
setwd('Z:/Contextual_Cueing/Experiment 2/Data')
library(tidyverse)
library(ez)
library(broom)
library(BayesFactor)
### to make custom number of ticks on axes
number_ticks <- function(n) {function(limits) pretty(limits, n)}
every_nth <- function(x, nth, empty = TRUE, inverse = FALSE)
{
if (!inverse) {
if(empty) {
x[1:nth == 1] <- ""
x
} else {
x[1:nth != 1]
}
} else {
if(empty) {
x[1:nth != 1] <- ""
x
} else {
x[1:nth == 1]
}
}
}
all_files = list.files(pattern=".csv")
all_data <- do.call(rbind, lapply(all_files, read.csv, header=TRUE))
all_data$q1 <- as.numeric(all_data$q1)
all_data$q2 <- as.numeric(as.character(all_data$q2))
descrip <- all_data %>%
mutate(hit = ifelse(Error == 0, 1, 0)) %>%
group_by(sub_id) %>%
summarise(accuracy = mean(hit))
bad_subs <- (descrip %>%
filter(accuracy < .9))$sub_id
n_subs <- nrow(descrip) - length(bad_subs)
clean_data <- all_data %>%
filter(!is.element(sub_id, bad_subs)) %>%
filter(Error == 0) %>%
group_by(repeat., d_setsize, sub_id) %>%
mutate(upperlimit = mean(RT) + 2.5*sd(RT), lowerlimit = mean(RT) - 2.5*sd(RT)) %>%
mutate(outlier = RT > upperlimit | RT < lowerlimit) %>%
filter(outlier == FALSE) %>%
mutate(epoch = ceiling(block/5))
clean_df <- clean_data %>%
mutate(display = if_else(repeat. ==0, 'new', 'old')) %>%
group_by(display, d_setsize, epoch, sub_id) %>%
summarise(rt = mean(RT), q1 = mean(q1), q2 = mean(q2))
clean_df$display <- as.factor(clean_df$display)
clean_df$epoch <- as.factor(clean_df$epoch)
overall_plot <- clean_df %>%
group_by(display, epoch) %>%
summarise(mean_rt = mean(rt), sem = sd(rt)/sqrt(20))
overall_plot$epoch <- as.factor(overall_plot$epoch)
ggplot(overall_plot , aes(x=epoch, y=mean_rt, linetype = display, group=display)) +
geom_point(size=5, color = '#E84A27') +
geom_line(size=3, color = '#E84A27') +
geom_errorbar(aes(ymin=mean_rt-sem, ymax=mean_rt+sem), width=.3, size=1, color = '#E84A27') +
coord_cartesian(ylim=c(850, 1100)) +
xlab("Epoch") +
ylab("RT") +
scale_y_continuous(breaks=seq(850,1100,10),
labels = every_nth(seq(850,1100,10), 5, inverse=TRUE)) +
theme_bw() +
theme(panel.border = element_rect(linetype = 'solid', colour = 'grey', size=1.2),
text = element_text(size=28)) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
theme(legend.position="none",
axis.text=element_text(size=28)) +
theme(panel.border = element_blank())
lure_plot <- clean_df %>%
group_by(display, d_setsize) %>%
summarise(mean_rt = mean(rt), sem = sd(rt)/sqrt(n_subs))
ggplot(lure_plot , aes(x=d_setsize, y=mean_rt, linetype = display, group=display)) +
geom_point(size=5) +
stat_smooth(method="lm", formula=y~log(x+1), se=FALSE, size = 3.5, color='#13294B') +
geom_errorbar(aes(ymin=mean_rt-sem, ymax=mean_rt+sem), width=1, size=1) +
xlab("Lure setsize") +
ylab("RT") +
coord_cartesian(ylim=c(850,1100)) +
scale_y_continuous(breaks=seq(850,1100,10),
labels = every_nth(seq(850,1100,10), 5, inverse=TRUE)) +
theme_bw() +
theme(panel.border = element_rect(linetype = 'solid', colour = 'grey', size=1.2),
text = element_text(size=28)) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
theme(legend.position="none",
axis.text=element_text(size=28)) +
theme(panel.border = element_blank())
clean_df$epoch <- as.factor(clean_df$epoch)
clean_df$d_setsize <- as.factor(clean_df$d_setsize)
ezANOVA(clean_df,
dv = rt,
wid = sub_id,
within = c(epoch, d_setsize, display))
descriptive_stats <- clean_df %>%
spread(display, rt) %>%
mutate(cc_effect = old - new) %>%
group_by(epoch) %>%
summarise(meanRT = mean(cc_effect),
SD = sd(cc_effect))
ezANOVA(clean_df,
dv = rt,
wid = sub_id,
within = c(epoch, d_setsize, display))
all_ps <- list()
all_ts <- list()
for(i in 1:5){
test<- t.test((clean_df %>% filter(epoch == i & display == "old"))$rt,
(clean_df %>% filter(epoch == i & display == "new"))$rt, paired = TRUE)
all_ps <- c(all_ps, test$p.value)
all_ts <- c(all_ts, test$statistic)
}
View(all_ps)
View(all_ts)
View(all_ts)
rm(list=ls())
setwd('Z:/Contextual_Cueing/Experiment 1/Data')
library(tidyverse)
library(ez)
library(broom)
library(BayesFactor)
### to make custom number of ticks on axes
number_ticks <- function(n) {function(limits) pretty(limits, n)}
every_nth <- function(x, nth, empty = TRUE, inverse = FALSE)
{
if (!inverse) {
if(empty) {
x[1:nth == 1] <- ""
x
} else {
x[1:nth != 1]
}
} else {
if(empty) {
x[1:nth != 1] <- ""
x
} else {
x[1:nth == 1]
}
}
}
all_files = list.files(pattern=".csv")
all_data <- do.call(rbind, lapply(all_files, read.csv, header=TRUE))
all_data$q1 <- as.numeric(all_data$q1)
all_data$q2 <- as.numeric(all_data$q2)
descrip <- all_data %>%
mutate(hit = ifelse(Error == 0, 1, 0)) %>%
group_by(sub_id) %>%
summarise(accuracy = mean(hit))
bad_subs <- (descrip %>%
filter(accuracy < .9))$sub_id
n_subs <- length(all_files) - length(bad_subs)
clean_data <- all_data %>%
filter(!is.element(sub_id, bad_subs)) %>%
filter(Error == 0) %>%
group_by(repeat., d_setsize, sub_id) %>%
mutate(upperlimit = mean(RT) + 2.5*sd(RT), lowerlimit = mean(RT) - 2.5*sd(RT)) %>%
mutate(outlier = RT > upperlimit | RT < lowerlimit) %>%
filter(outlier == FALSE) %>%
mutate(epoch = ceiling(block/5))
clean_df <- clean_data %>%
group_by(repeat., d_setsize, epoch, sub_id) %>%
summarise(rt = mean(RT), q1 = mean(q1), q2 = mean(q2)) %>%
mutate(display = if_else(repeat. ==0, 'new', 'old'))
clean_df$display <- as.factor(clean_df$display)
clean_df$epoch <- as.factor(clean_df$epoch)
q2 <- clean_df %>%
group_by(sub_id) %>%
summarize(perc = mean(q2, na.rm=TRUE))
percent_noticed <- mean(clean_df$q1)
expt1_q2 <- q2
expt1_q2 <- expt1_q2 %>% mutate(expt = 1)
plot_df <- clean_df %>%
group_by(epoch, d_setsize, display) %>%
summarise(mean_rt = mean(rt), sem = sd(rt/sqrt(n_subs)))
View(expt1_q2)
plot_df$epoch <- as.factor(plot_df$epoch)
plot_df$display <- as.factor(plot_df$display)
plot_df$d_setsize <- as.factor(plot_df$d_setsize)
ggplot(plot_df, aes(x=epoch, y=mean_rt, linetype = display, group=interaction(d_setsize, display), color=d_setsize)) +
geom_point(data=plot_df, aes(color=d_setsize, shape = d_setsize), size=4) +
geom_errorbar(aes(ymin=mean_rt-sem, ymax=mean_rt+sem), size=1, width=.3) +
geom_line( size=1) +
# facet_wrap(~ sub_id) +
xlab("Epoch") +
ylab("RT") +
# scale_y_continuous(limits=c(650, 1000)) +
# ggtitle("8 Candidates") +
coord_cartesian(ylim=c(650,1050))+
scale_color_manual(values=c('#13294b', '#E84A27'), labels = c("4", "8")) +
# scale_y_continuous(breaks=number_ticks(6)) +
scale_y_continuous(breaks=seq(650,1050,10),
labels = every_nth(seq(650,1050,10), 5, inverse=TRUE)) +
theme_bw() +
theme(panel.border = element_rect(linetype = 'solid', colour = 'grey', size=1.2),
text = element_text(size=18)) +
theme(panel.border = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
theme(legend.position="bottom",
axis.text=element_text(size=18)) +
theme(legend.position = "none")
clean_df$d_setsize <- as.factor(clean_df$d_setsize)
anovaBF(rt ~ display * d_setsize *  epoch, data =clean_df)
descriptive_stats <- clean_df %>%
group_by(epoch) %>%
summarise(meanRT = mean(rt),
SD = sd(rt))
ezANOVA(clean_df,
dv = rt,
wid = sub_id,
within = .(d_setsize, display, epoch))
percent_noticed <- mean(clean_df$q1)
