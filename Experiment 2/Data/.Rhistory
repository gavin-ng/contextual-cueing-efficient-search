View(a)
View(df)
a<- sapply(df, max)
a<- apply(df, max)
a<- lapply(df, max)
df <- replicate(10, rnorm(11.36, 2.82))
mini = c(mini, min(df[i]))
for (i = 1:nrow(df)){
maxi = c(maxi, max(df[i]))
mini = c(mini, min(df[i]))
}
maxi <- ()
mini <- ()
maxi <- list()
mini <- list()
for (i = 1:nrow(df)){
maxi = c(maxi, max(df[i]))
mini = c(mini, min(df[i]))
}
for (i in 1:nrow(df)){
maxi = c(maxi, max(df[i]))
mini = c(mini, min(df[i]))
}
maxi
View(df)
df
df[1]
df[1,]
maxi <- list()
mini <- list()
for (i in 1:nrow(df)){
maxi = c(maxi, max(df[i,]))
mini = c(mini, min(df[i,]))
}
df <- replicate(10000, rnorm(11.36, 2.82))
maxi <- list()
mini <- list()
for (i in 1:nrow(df)){
maxi = c(maxi, max(df[i,]))
mini = c(mini, min(df[i,]))
}
sd(maxi)
maxi <- list()
mini <- list()
for (i in 1:nrow(df)){
maxi = c(maxi, max(df[i,]))
mini = c(mini, min(df[i,]))
}
df <- replicate(1000, rnorm(11.36, 2.82))
maxi <- list()
mini <- list()
for (i in 1:nrow(df)){
maxi = c(maxi, max(df[i,]))
mini = c(mini, min(df[i,]))
}
View(mini)
View(maxi)
nrow(df)
length(df)
for (i in 1:length(df)){
maxi = c(maxi, max(df[i,]))
mini = c(mini, min(df[i,]))
}
maxi <- list()
mini <- list()
for (i in 1:length(df)){
maxi = c(maxi, max(df[,i]))
mini = c(mini, min(df[,i]))
}
rnorm(11.36, 2.82)
rnorm(11.36, 2.82, 1)
df <- replicate(100, rnorm(1, 11.36, 2.82))
maxi <- list()
mini <- list()
for (i in 1:length(df)){
maxi = c(maxi, max(df[,i]))
mini = c(mini, min(df[,i]))
}
maxi <- list()
mini <- list()
for (i in 1:nrow(df)){
maxi = c(maxi, max(df[i,]))
mini = c(mini, min(df[i,]))
}
maxi = c(maxi, max(df[i,]))
df[1]
df[1,]
df[,1]
df <- replicate(100, rnorm(20, 11.36, 2.82))
maxi <- list()
mini <- list()
for (i in 1:nrow(df)){
maxi = c(maxi, max(df[i,]))
mini = c(mini, min(df[i,]))
}
sd(maxi)
View(maxi)
View(mini)
View(df)
View(maxi)
df <- replicate(1000, rnorm(20, 11.36, 2.82))
mini <- list()
maxi <_ list()
for (i = 1:nrow(df)){
mini <- c(mini, min(df[i,]))
maxi <- c(maxi, max(df[i,]))
}
mini <- list()
maxi <- list()
for (i = 1:nrow(df)){
mini <- c(mini, min(df[i,]))
maxi <- c(maxi, max(df[i,]))
}
for (i in 1:nrow(df)){
mini <- c(mini, min(df[i,]))
maxi <- c(maxi, max(df[i,]))
}
mini <- list()
maxi <- list()
for (i in 1:nrow(df)){
mini <- c(mini, min(df[i,]))
maxi <- c(maxi, max(df[i,]))
}
sd(mini)
sd(as.numeric(mini))
sd(as.numeric(max))
sd(as.numeric(maxi))
quant_75 <- quantile(mini)
quant_75 <- quantile(as.numeric(mini))
quant_75 <- quantile(as.numeric(mini))[4]
mini <- list()
maxi <- list()
mini_quant <- list()
maxi_quant <- list()
for (i in 1:nrow(df)){
mini <- c(mini, min(df[i,]))
maxi <- c(maxi, max(df[i,]))
mini_quant <- c(mini_quant, quantile(as.numeric(mini))[4])
maxi_quant <- c(maxi_quant, quantile(as.numeric(maxi))[4])
}
sd(as.numeric(mini))
sd(as.numeric(maxi))
df <- replicate(1000, rnorm(20, 40, 25))
mini <- list()
maxi <- list()
mini_quant <- list()
maxi_quant <- list()
for (i in 1:nrow(df)){
mini <- c(mini, min(df[i,]))
maxi <- c(maxi, max(df[i,]))
mini_quant <- c(mini_quant, quantile(as.numeric(mini))[4])
maxi_quant <- c(maxi_quant, quantile(as.numeric(maxi))[4])
}
sd(as.numeric(mini))
sd(as.numeric(maxi))
setwd('Z:/Contextual_Cueing/Experiment 2/Data')
######## LIBRARIES ########
library(tidyverse)
library(ez)
library(broom)
library(BayesFactor)
####### FUNCTIONS ########
### to make custom number of ticks on axes
number_ticks <- function(n) {function(limits) pretty(limits, n)}
every_nth <- function(x, nth, empty = TRUE, inverse = FALSE)
{
if (!inverse) {
if(empty) {
x[1:nth == 1] <- ""
x
} else {
x[1:nth != 1]
}
} else {
if(empty) {
x[1:nth != 1] <- ""
x
} else {
x[1:nth == 1]
}
}
}
all_files = list.files(pattern=".csv")
all_data <- do.call(rbind, lapply(all_files, read.csv, header=TRUE))
all_data$q1 <- as.numeric(all_data$q1)
all_data$q2 <- as.numeric(as.character(all_data$q2))
descrip <- all_data %>%
mutate(hit = ifelse(Error == 0, 1, 0)) %>%
group_by(sub_id) %>%
summarise(accuracy = mean(hit))
bad_subs <- (descrip %>%
filter(accuracy < .9))$sub_id
n_subs <- nrow(descrip) - length(bad_subs)
clean_data <- all_data %>%
filter(!is.element(sub_id, bad_subs)) %>%
filter(Error == 0) %>%
group_by(repeat., d_setsize, sub_id) %>%
mutate(upperlimit = mean(RT) + 2.5*sd(RT), lowerlimit = mean(RT) - 2.5*sd(RT)) %>%
mutate(outlier = RT > upperlimit | RT < lowerlimit) %>%
filter(outlier == FALSE) %>%
mutate(epoch = ceiling(block/5))
clean_df <- clean_data %>%
mutate(display = if_else(repeat. ==0, 'new', 'old')) %>%
group_by(display, d_setsize, epoch, sub_id) %>%
summarise(rt = mean(RT), q1 = mean(q1), q2 = mean(q2))
clean_df$display <- as.factor(clean_df$display)
clean_df$epoch <- as.factor(clean_df$epoch)
clean_df$epoch <- as.factor(clean_df$epoch)
clean_df$d_setsize <- as.factor(clean_df$d_setsize)
ezANOVA(clean_df,
dv = rt,
wid = sub_id,
within = c(epoch, d_setsize, display))
rm(list=ls())
setwd('Z:/Contextual_Cueing/Experiment 3/Data')
library(tidyverse)
library(ez)
library(broom)
library(BayesFactor)
## Functions
every_nth <- function(x, nth, empty = TRUE, inverse = FALSE)
{
if (!inverse) {
if(empty) {
x[1:nth == 1] <- ""
x
} else {
x[1:nth != 1]
}
} else {
if(empty) {
x[1:nth != 1] <- ""
x
} else {
x[1:nth == 1]
}
}
}
all_files = list.files(pattern=".csv")
recognition_files = list.files(pattern="recognition.csv")
search_files = setdiff(all_files, c(recognition_files, "question2_resp.csv"))
search_data <- do.call(rbind, lapply(search_files, read.csv, header=TRUE))
recognition_data <- do.call(rbind, lapply(recognition_files, read.csv, header = TRUE))
q2_data <- read.csv("question2_resp.csv") %>%
rename(sub_id_2 = "Var1",
q2_resp = "Var2")
descrip <- search_data %>%
filter(sub_id != 28) %>%
mutate(hit = ifelse(Error == 0, 1, 0)) %>%
group_by(sub_id) %>%
summarise(accuracy = mean(hit))
individual_mean_rts <- search_data %>%
filter(sub_id != 28) %>%
filter(Error == 0) %>%
group_by(sub_id) %>%
summarise(meanRT = mean(RT))
group_sd <- sd(individual_mean_rts$meanRT)
group_mean <- mean(individual_mean_rts$meanRT)
bad_subs_accuracy <- (descrip %>%
filter(accuracy<.9))$sub_id
bad_subs_rt <- (individual_mean_rts %>%
mutate(upper_sd = group_mean + (2*group_sd),
lower_sd = group_mean - (2*group_sd)) %>%
mutate(exclude = if_else(meanRT < lower_sd | meanRT > upper_sd, 1, 0)) %>%
filter(exclude == 1))$sub_id
## again, with subject 19 excluded
descrip <- search_data %>%
filter(sub_id != bad_subs_rt) %>%
mutate(hit = ifelse(Error == 0, 1, 0)) %>%
group_by(sub_id) %>%
summarise(accuracy = mean(hit))
individual_mean_rts <- search_data %>%
filter(sub_id != bad_subs_rt) %>%
filter(Error == 0) %>%
group_by(sub_id) %>%
summarise(meanRT = mean(RT))
group_sd <- sd(individual_mean_rts$meanRT)
group_mean <- mean(individual_mean_rts$meanRT)
bad_subs_rt <- (individual_mean_rts %>%
mutate(upper_sd = group_mean + (2*group_sd),
lower_sd = group_mean - (2*group_sd)) %>%
mutate(exclude = if_else(meanRT < lower_sd | meanRT > upper_sd, 1, 0)) %>%
filter(exclude == 1))$sub_id
bad_subs <- 19
n_subs <- 20
clean_data <- search_data %>%
filter(!is.element(sub_id, bad_subs)) %>%
filter(Error == 0) %>%
group_by(repeat., d_setsize, sub_id) %>%
mutate(upperlimit = mean(RT) + 2.5*sd(RT), lowerlimit = mean(RT) - 2.5*sd(RT)) %>%
mutate(outlier = RT > upperlimit | RT < lowerlimit) %>%
mutate(display = if_else(repeat. == 0, 'new', 'old')) %>%
filter(outlier == FALSE) %>%
mutate(epoch = ceiling(block/5))
clean_df <- clean_data %>%
group_by(display, d_setsize, epoch, sub_id) %>%
summarise(rt = mean(RT))
clean_df$display <- as.factor(clean_df$display)
clean_df$epoch <- as.factor(clean_df$epoch)
plot_df <- clean_df %>%
group_by(display, d_setsize) %>%
summarise(mean_rt = mean(rt), sem = sd(rt/sqrt(20)))
## 0, 4, 16, 26
ggplot(plot_df, aes(x=d_setsize, y=mean_rt, linetype = display, group=display)) +
geom_point(size=3, aes(shape = plot_df$display)) +
stat_smooth(method="lm", formula=y~log(x+1), se=FALSE, color='#13294b', size = 2) +
geom_errorbar(aes(ymin=mean_rt-sem, ymax=mean_rt+sem), width=2, size=1) +
xlab("Lure set size") +
ylab("RT") + coord_cartesian(ylim=c(460, 660)) +
scale_y_continuous(breaks=seq(460, 660,10),
labels = every_nth(seq(460, 660,10), 5, inverse=TRUE)) +
theme_bw() +
theme(panel.border = element_rect(linetype = 'solid', colour = 'grey', size=1.2),
text = element_text(size=28)) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
theme(legend.position="none",
axis.text=element_text(size=28)) +
theme(panel.border = element_blank())
plot_df_epoch <- clean_df %>%
group_by(epoch, display) %>%
summarise(mean_rt = mean(rt), sem = sd(rt/sqrt(20)))
ggplot(plot_df_epoch, aes(x=epoch, y=mean_rt, linetype = display, shape=display, group=display)) +
geom_point(size=4, color="#E84A27") +
geom_line(size=2, color="#E84A27") +
# stat_smooth(method="lm", formula=y~log(x+1), se=FALSE, color='#E84A27', size = 3.5) +
geom_errorbar(aes(ymin=mean_rt-sem, ymax=mean_rt+sem), width=0.3, size=1, color="#E84A27") +
# facet_wrap(~ sub_id) +
xlab("Epoch") +
ylab("RT") +
coord_cartesian(ylim=c(460, 660)) +
# scale_color_manual(values=c('#13294b', '#000099', '#00004C', '#000033', "000000")) +
# scale_y_continuous(breaks=number_ticks(6)) +
scale_y_continuous(breaks=seq(460, 660,10),
labels = every_nth(seq(460, 660,10), 5, inverse=TRUE)) +
theme_bw() +
theme(panel.border = element_rect(linetype = 'solid', colour = 'grey', size=1.2),
text = element_text(size=28)) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
theme(legend.position="none",
axis.text=element_text(size=28)) +
theme(panel.border = element_blank())
clean_df$d_setsize <- as.factor(clean_df$d_setsize)
bf <- anovaBF(rt ~ d_setsize * epoch* display, data = clean_df)
##### Stats #####
clean_df$epoch <- as.factor(clean_df$epoch)
clean_df$d_setsize <- as.factor(clean_df$d_setsize)
ezANOVA(clean_df,
dv = rt,
wid = sub_id,
within = c(epoch, d_setsize, display))
bf
rm(list=ls())
setwd('Z:/Contextual_Cueing/Experiment 2/Data')
######## LIBRARIES ########
library(tidyverse)
library(ez)
library(broom)
library(BayesFactor)
####### FUNCTIONS ########
### to make custom number of ticks on axes
number_ticks <- function(n) {function(limits) pretty(limits, n)}
every_nth <- function(x, nth, empty = TRUE, inverse = FALSE)
{
if (!inverse) {
if(empty) {
x[1:nth == 1] <- ""
x
} else {
x[1:nth != 1]
}
} else {
if(empty) {
x[1:nth != 1] <- ""
x
} else {
x[1:nth == 1]
}
}
}
######## MAIN ########
all_files = list.files(pattern=".csv")
all_data <- do.call(rbind, lapply(all_files, read.csv, header=TRUE))
all_data$q1 <- as.numeric(all_data$q1)
all_data$q2 <- as.numeric(as.character(all_data$q2))
descrip <- all_data %>%
mutate(hit = ifelse(Error == 0, 1, 0)) %>%
group_by(sub_id) %>%
summarise(accuracy = mean(hit))
bad_subs <- (descrip %>%
filter(accuracy < .9))$sub_id
n_subs <- nrow(descrip) - length(bad_subs)
clean_data <- all_data %>%
filter(!is.element(sub_id, bad_subs)) %>%
filter(Error == 0) %>%
group_by(repeat., d_setsize, sub_id) %>%
mutate(upperlimit = mean(RT) + 2.5*sd(RT), lowerlimit = mean(RT) - 2.5*sd(RT)) %>%
mutate(outlier = RT > upperlimit | RT < lowerlimit) %>%
filter(outlier == FALSE) %>%
mutate(epoch = ceiling(block/5))
clean_df <- clean_data %>%
mutate(display = if_else(repeat. ==0, 'new', 'old')) %>%
group_by(display, d_setsize, epoch, sub_id) %>%
summarise(rt = mean(RT), q1 = mean(q1), q2 = mean(q2))
clean_df$display <- as.factor(clean_df$display)
clean_df$epoch <- as.factor(clean_df$epoch)
##### PLOT #####
overall_plot <- clean_df %>%
group_by(display, epoch) %>%
summarise(mean_rt = mean(rt), sem = sd(rt)/sqrt(20))
overall_plot$epoch <- as.factor(overall_plot$epoch)
## 0, 4, 16, 26
ggplot(overall_plot , aes(x=epoch, y=mean_rt, linetype = display, group=display)) +
geom_point(size=5, color = '#E84A27') +
geom_line(size=3, color = '#E84A27') +
geom_errorbar(aes(ymin=mean_rt-sem, ymax=mean_rt+sem), width=.3, size=1, color = '#E84A27') +
coord_cartesian(ylim=c(850, 1100)) +
xlab("Epoch") +
ylab("RT") +
scale_y_continuous(breaks=seq(850,1100,10),
labels = every_nth(seq(850,1100,10), 5, inverse=TRUE)) +
theme_bw() +
theme(panel.border = element_rect(linetype = 'solid', colour = 'grey', size=1.2),
text = element_text(size=28)) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
theme(legend.position="none",
axis.text=element_text(size=28)) +
theme(panel.border = element_blank())
lure_plot <- clean_df %>%
group_by(display, d_setsize) %>%
summarise(mean_rt = mean(rt), sem = sd(rt)/sqrt(n_subs))
ggplot(lure_plot , aes(x=d_setsize, y=mean_rt, linetype = display, group=display)) +
geom_point(size=5) +
stat_smooth(method="lm", formula=y~log(x+1), se=FALSE, size = 3.5, color='#13294B') +
geom_errorbar(aes(ymin=mean_rt-sem, ymax=mean_rt+sem), width=1, size=1) +
xlab("Lure setsize") +
ylab("RT") +
coord_cartesian(ylim=c(850,1100)) +
scale_y_continuous(breaks=seq(850,1100,10),
labels = every_nth(seq(850,1100,10), 5, inverse=TRUE)) +
theme_bw() +
theme(panel.border = element_rect(linetype = 'solid', colour = 'grey', size=1.2),
text = element_text(size=28)) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
theme(legend.position="none",
axis.text=element_text(size=28)) +
theme(panel.border = element_blank())
##### Stats #####
clean_df$epoch <- as.factor(clean_df$epoch)
clean_df$d_setsize <- as.factor(clean_df$d_setsize)
ezANOVA(clean_df,
dv = rt,
wid = sub_id,
within = c(epoch, d_setsize, display))
descriptive_stats <- clean_df %>%
spread(display, rt) %>%
mutate(cc_effect = old - new) %>%
group_by(epoch) %>%
summarise(meanRT = mean(cc_effect),
SD = sd(cc_effect))
clean_df$d_setsize <- as.numeric(as.character(clean_df$d_setsize))
old_slopes <- clean_df %>%
group_by(d_setsize, display, sub_id) %>%
filter(display == "old") %>%
summarise(meanRT = mean(rt)) %>%
group_by(sub_id) %>%
do(log_slope = lm(meanRT ~ log(d_setsize+1), data =.)) %>%
tidy(log_slope) %>%
filter(term == "log(d_setsize + 1)") %>%
mutate(display = "old")
new_slopes <- clean_df %>%
group_by(d_setsize, display, sub_id) %>%
filter(display == "new") %>%
summarise(meanRT = mean(rt)) %>%
group_by(sub_id) %>%
do(log_slope = lm(meanRT ~ log(d_setsize+1), data =.)) %>%
tidy(log_slope) %>%
filter(term == "log(d_setsize + 1)") %>%
mutate(display = "new")
all_slopes <- rbind(old_slopes, new_slopes)
ezANOVA(all_slopes,
wid = sub_id,
dv = estimate,
within = display)
# slopes not statistically significant
# let's try Bayes Factors
all_slopes$display <- as.factor(all_slopes$display)
anovaBF(estimate ~ display, data = all_slopes)
1/0.3101588
rm(list=ls())
install.packages("GGally")
install.packages("data sets")
install.packages("data_set")
install.packages("data_sets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
library(tree)
library(datasets)
df <- tree
df <- trees
ggpairs
library(GGally)
library(tidyverse)
ggpairs(data = df, columns = 1:3)
install.packages("caret")
